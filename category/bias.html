<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>Bias Facial Recognition - Bias</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">Bias Facial Recognition</a></h1>
                <nav><ul>
                    <li class="active"><a href="/category/bias.html">Bias</a></li>
                    <li><a href="/category/how-it-works.html">How It Works</a></li>
                    <li><a href="/category/introduction.html">Introduction</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="/overall-biases.html">Overall Biases</a></h1>
<footer class="post-info">
        <abbr class="published" title="2020-03-02T19:30:00-05:00">
                Published: Mon 02 March 2020
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/hannah-agwunobi.html">Hannah Agwunobi</a>
        </address>
<p>In <a href="/category/bias.html">Bias</a>.</p>

</footer><!-- /.post-info --><h1>Overall "Biases"</h1>
<p>When referring to facial recognition technology, people often use vague terms to describe "bias" in the systems. Simply put, when speaking on facial recognition bias purely in a technological sense, it refers to the disparities between facial recognition software's performance on people of color and women compared to white men.</p>
<p>Specifically, a <a href="https://www.nist.gov/programs-projects/face-recognition-vendor-test-frvt-ongoing">federal study</a> in 2019 of almost 200 facial recognition algorithms  found that some of these algorithms were up to 100 times more likely to confuse two people of color with each other than they were to confuse two caucasian people with each other. Black, asian, and native american people in particular were the most likely to be misidentified. Black women were also likelier than other groups to be falsely identified using the FBI's mugshot database.</p>
<p><img alt="Black Man Facial Recognition" src="images/black_man_face.jpg"></p>
<p>Another study called <a href="http://gendershades.org/overview.html">Gender Shades</a> was done in 2018 by researches the MIT Media Lab, and it tested 3 facial recognition algorithms from prominent companies (Microsoft, IBM, Face++). It found that darker skinned people as a whole were 11-20% more likely to be misidentified than lighter skinned people, varying depending on the algorithm.</p>
<p><img alt="Gender Shades Example" src="images/Gender_Shades.jpg"></p>
<p>Gender Shades also found that women were much more commonly misidentified than men, with the three algorithms having error rates for women 8-20% higher than error rates for men. Also, due tothe strictly "female" and "male" categories for facial recognition classifications, the algorithms perform much worse on people who don't strictly conform to the gender binary (i.e. women with short hair, men who wear makeup, and nonbinary and transgender people). After Uber's Real-Time ID Check security feature was rolled out in 2016, some transgender Uber drivers experienced being locked out of their accounts because the facial recognition system couldn't identify them as their photos before they transitioned.</p>
<p><img alt="Woman Example" src="images/woman.jpg"></p>
<p>These are just a few examples of how prominent facial recognition technology performs worse on people of color and women, but these performance issues brought many researchers to the question: why? Where is the bias?</p>
<h1>Technological Bias</h1>
<p>This performance on people of color and women could be affected by many technical factors. Namely, even in the first step of the facial recognition process, some people of color are left out or misidentified; sometimes, facial recognition algorithms cannot detect darker skinned faces at all. This can be due to poor contrast with the background or suboptimal image conditions; in fact, a study found that African American people have a disproportionately high number of images with poor lighting in many facial recognition databases.</p>
<p>Some of this performance bias could also be explained by a lack of diversity in the datasets this software is trained on. Some datasets consist of celebrities in Hollywood, in which minorities are historically underrepresented, which can lead to less accurate matching for people of color. There was a dataset called Faces in the Wild that many earlier facial recognition algorithms used for training, but a study later found that it was 77% male and 83% white.</p>
<h1>Historical Biases</h1>
<p>Facial recognition algorithms also must be viewed within their societal context. Any performance bias within facial recognition technology is also implicitly influenced by the people creating the software and who it's designed for. For example, due to the lack of diversity in artificial intelligence, the concept of "own-race bias" is very prevalent in facial recognition.</p>
<p>"Own-race bias" viewed through the lens of facial recognition details how the algorithms produced are also subconciously populated with the bias of the people who make them. People naturally identify those within their own racial group better; for example, a 2011 study showed that algorithms developed in China, Japan, and South Korea recognized east Asian faces better than Caucasian faces, whereas for algorithms developed in the United States, France, and Germany, the converse was true.</p>                </article>
            </aside><!-- /#featured -->
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="http://getpelican.com/">Pelican</a></li>
                            <li><a href="http://python.org/">Python.org</a></li>
                            <li><a href="http://jinja.pocoo.org/">Jinja2</a></li>
                            <li><a href="#">You can modify those links in your config file</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="#">You can add links in your config file</a></li>
                            <li><a href="#">Another social link</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>